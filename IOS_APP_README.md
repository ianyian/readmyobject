# Poker Chip Detector - iOS App

A native iOS application that uses custom YOLOv8 machine learning model to detect and count poker chips by color in real-time.

## ğŸ¯ Features

### Core Functionality

- ğŸ“¸ **Camera Capture**: Take photos using iPhone back camera
- ğŸ–¼ï¸ **Photo Library**: Analyze existing photos from library
- ğŸ¤– **AI Detection**: Powered by custom YOLOv8 Core ML model
- ğŸ¨ **Visual Results**: Bounding boxes with color-coded labels
- ğŸ“Š **Detailed Counts**: Total chips and breakdown by color
- âš¡ **Fast Processing**: Optimized for iOS Neural Engine

### Detected Chip Colors

- âš« **Black** poker chips
- ğŸŸ¢ **Green** poker chips
- ğŸ”´ **Red** poker chips
- âšª **White-Blue** poker chips

## ğŸ“± Screenshots & UI

### Main Screen

- Welcome screen with app branding
- Two main action buttons:
  - "Take Photo" (blue) - Opens camera
  - "Choose from Library" (green) - Opens photo picker
- Color legend showing detectable chip types

### Detection Results Screen

- Original image with overlaid bounding boxes
- Each detection labeled with:
  - Chip color name
  - Confidence percentage
- Summary card showing:
  - Total chips detected
  - Breakdown by color with icons
  - Processing time

## ğŸ—ï¸ Architecture

### SwiftUI + MVVM Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ContentView.swift          â”‚  Main UI & Navigation
â”‚  (Coordinator for camera & results) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CameraView.swift      â”‚  â”‚ ChipDetectionVM      â”‚
â”‚ PhotoPicker.swift     â”‚  â”‚ (Vision + Core ML)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚ best.mlpackage      â”‚
                           â”‚ (YOLOv8 Core ML)    â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

#### **Models/** (`ChipDetection.swift`)

- `Detection` - Single chip detection with bounding box, color, confidence
- `ChipColor` - Enum for chip types with display properties
- `DetectionResult` - Complete detection session with statistics

#### **ViewModels/** (`ChipDetectionViewModel.swift`)

- Loads Core ML model
- Processes images using Vision framework
- Converts model output to Detection objects
- Handles errors and loading states

#### **Views/**

- `CameraView.swift` - UIKit camera wrapper for SwiftUI
- `DetectionResultView.swift` - Results display with bounding boxes
- `ContentView.swift` - Main app coordinator

## ğŸ› ï¸ Technical Details

### Requirements

- **iOS:** 15.0+
- **Xcode:** 14.0+
- **Swift:** 5.0+
- **Frameworks:**
  - SwiftUI
  - Vision
  - Core ML
  - UIKit (Camera)

### Model Integration

- **Format:** Core ML (.mlpackage)
- **Input:** 640Ã—640 RGB image
- **Output:** Bounding boxes with class labels
- **Inference:** Vision framework with VNCoreMLRequest
- **Hardware:** Neural Engine, GPU, or CPU

### Performance

- **Inference Time:** 0.1-0.5 seconds (device dependent)
- **Frame Rate:** Suitable for real-time video (20-60 FPS)
- **Model Size:** ~6-50 MB (depending on YOLOv8 variant)
- **Memory:** Minimal impact, runs on all modern iPhones

## ğŸ“‚ File Structure

```
readmyobject/
â”œâ”€â”€ Models/
â”‚   â””â”€â”€ ChipDetection.swift           # Data models
â”œâ”€â”€ ViewModels/
â”‚   â””â”€â”€ ChipDetectionViewModel.swift  # Detection logic
â”œâ”€â”€ Views/
â”‚   â”œâ”€â”€ CameraView.swift              # Camera capture
â”‚   â””â”€â”€ DetectionResultView.swift     # Results display
â”œâ”€â”€ ContentView.swift                 # Main UI
â”œâ”€â”€ readmyobjectApp.swift            # App entry point
â”œâ”€â”€ Info.plist                        # Permissions
â””â”€â”€ Assets.xcassets/                  # App assets
```

## ğŸ”’ Privacy & Permissions

### Required Permissions

- **Camera**: Capture photos for chip detection
- **Photo Library**: Select existing photos to analyze

### Privacy Features

- âœ… All processing done on-device
- âœ… No data sent to servers
- âœ… No image storage without user action
- âœ… Clear permission descriptions

## ğŸ¨ Design Highlights

### Color Scheme

- **Primary:** Blue (main actions)
- **Secondary:** Green (alternative actions)
- **Accent:** Color-coded by chip type
- **Background:** Light/adaptive

### Typography

- **Headers:** Bold system font
- **Body:** Regular system font
- **Labels:** Semibold for emphasis

### UI/UX

- Large, tappable buttons
- Clear visual hierarchy
- Loading indicators
- Error alerts
- Dismissible sheets

## ğŸš€ Setup & Installation

See [QUICK_START.md](QUICK_START.md) for 5-minute setup or [IOS_SETUP_GUIDE.md](IOS_SETUP_GUIDE.md) for detailed instructions.

**Quick Version:**

1. Convert model: `python convert_to_coreml.py`
2. Open Xcode: `open readmyobject.xcodeproj`
3. Add `best.mlpackage` to project
4. Add all Swift files to project
5. Build & Run

## ğŸ“Š Model Details

### YOLOv8 Custom Model

- **Trained on:** Custom poker chip dataset
- **Classes:** 4 (Black, Green, Red, White-Blue)
- **Architecture:** YOLOv8 (Ultralytics)
- **Accuracy:** ~90%+ mAP on validation set
- **Confidence Threshold:** 0.5 (configurable)

See [MODEL_INFO.md](MODEL_INFO.md) for complete model documentation.

## ğŸ§ª Testing

### Recommended Test Cases

1. **Lighting conditions:** Bright, indoor, low-light
2. **Camera angles:** Top-down, 45Â°, side view
3. **Chip arrangements:** Scattered, stacked, mixed
4. **Distances:** Close-up, medium, far

### Test Data

Use validation images from `data/valid/images/`:

- Import to iOS photo library
- Test with "Choose from Library"
- Verify detection accuracy

## ğŸ› Known Limitations

- Overlapping chips may be counted as one
- Very low lighting reduces accuracy
- Extreme angles affect detection
- Minimum chip size for detection
- Best results with top-down view

## ğŸ”® Future Enhancements

### Planned Features

- [ ] Real-time video detection
- [ ] Adjustable confidence slider
- [ ] Save results to Photos
- [ ] Export as CSV/JSON
- [ ] Chip value calculation
- [ ] Detection history
- [ ] Multiple denomination support
- [ ] Dark mode optimization
- [ ] iPad specific layout
- [ ] Share results feature

### Advanced Features

- [ ] AR overlay in camera view
- [ ] Stack counting (multiple layers)
- [ ] Currency conversion
- [ ] Multi-table support
- [ ] Batch processing
- [ ] Cloud sync (optional)

## ğŸ“ Code Examples

### Basic Usage

```swift
// Initialize view model
let viewModel = ChipDetectionViewModel()

// Detect chips in image
viewModel.detectChips(in: capturedImage)

// Access results
if let result = viewModel.detectionResult {
    print("Total chips: \(result.totalChips)")
    print("Red chips: \(result.chipCounts[.red] ?? 0)")
}
```

### Adjust Confidence

```swift
// In ChipDetectionViewModel
var confidenceThreshold: Float = 0.3  // More detections
var confidenceThreshold: Float = 0.7  // Higher accuracy
```

### Custom Processing

```swift
// Filter detections by color
let redChips = result.detections(for: .red)
let highConfidence = result.detections.filter { $0.confidence > 0.8 }
```

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:

- UI/UX enhancements
- Performance optimizations
- Additional features
- Bug fixes
- Documentation

## ğŸ“„ License

MIT License - See main [README.md](README.md)

## ğŸ™ Acknowledgments

- **YOLOv8:** Ultralytics
- **Core ML:** Apple
- **Vision Framework:** Apple
- **SwiftUI:** Apple

## ğŸ“ Support

- **Documentation:** [IOS_SETUP_GUIDE.md](IOS_SETUP_GUIDE.md)
- **Model Info:** [MODEL_INFO.md](MODEL_INFO.md)
- **Quick Start:** [QUICK_START.md](QUICK_START.md)
- **Issues:** GitHub Issues
- **Discussions:** GitHub Discussions

---

**Built with â¤ï¸ for poker enthusiasts**

_Version 1.0 - December 24, 2025_
